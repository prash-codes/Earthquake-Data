# Earthquake-Data

## ðŸ“… Project Milestones & Due Dates

| Task                                     | Due Date     | Description |
|------------------------------------------|--------------|-------------|
| Ingest data into GCS using **PySpark**   | 2024-10-23   | Load data from API source into a Google Cloud Storage (GCS) bucket using PySpark to prepare for further processing. |
| Ingest data into GCS using **Dataflow**  | 2024-10-26   | Utilize Google Cloud Dataflow to stream or batch load data into a GCS bucket, ensuring efficient and scalable data ingestion. |
| Transformation using **PySpark**         | 2024-10-28   | Apply data transformation processes to the ingested data in the GCS bucket using PySpark, enriching the dataset. |
| Transformation using **Dataflow**        | 2024-10-31   | Leverage Google Cloud Dataflow to perform data transformation operations on the dataset in GCS, enabling real-time processing and analytics. |
| Load into BigQuery using **PySpark**     | 2024-11-05   | Load the transformed data from GCS into Google BigQuery using PySpark, making it available for analysis and reporting. |
| Load into BigQuery using **Dataflow**    | 2024-11-08   | Use Google Cloud Dataflow to ingest the transformed data into BigQuery for fast querying and analysis, ensuring optimized data loading. |
| Analysis using **PySpark**               | 2024-11-10   | Conduct analytical queries on the data stored in BigQuery using PySpark, generating insights needed. |
| Analysis using **Dataflow**              | 2024-11-12   | Utilize Google Cloud Dataflow to perform data analysis tasks on the data in BigQuery. |
| Analysis using **BigQuery SQL**          | 2024-11-14   | Formulate and execute SQL queries directly in BigQuery to derive insights from the data, focusing on specific analysis requirements. |
